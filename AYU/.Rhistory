version
tinytex::install_tinytex()
install.packages('tidyverse')
library(tidyverse)
library(ggplot2)
library(tidyverse)
version
library(tidyverse)
tinytex::install_tinytex()
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
Years_Experience <- c(1:20)
rand1 = rnorm(20, mean =  1, sd = .2)
rand2 =  rnorm(20, mean = 5, sd = 1)
Salary <- round(50 + 12*Years_Experience*rand1 + rand2, 2)
Gender <- c('Female', 'Male','Female', 'Male','Female', 'Male','Female', 'Male','Female', 'Male','Female', 'Male','Female', 'Male','Female', 'Male','Female', 'Male','Female', 'Male')
#summary(lm(Salary~Years_Experience))
library(tidyverse)
d <- tibble(Gender, Years_Experience, Salary)
knitr::kable(d)
# Solution
x = Years_Experience
y = Salary
print(paste('sum_x: ', sum(x)))
# Solution
x = Years_Experience
y = Salary
print(paste('sum_x: ', sum(x)))
print(paste('sum_y: ', sum(y)))
print(paste('sum_xy: ', sum(x*y)))
print(paste('sum_x^2: ', sum(x^2)))
print(paste('sum_y^2: ', sum(y^2)))
lm(y~x)
a = lm(y~x)
summary(a)
summary(a)$R
summary(a)$adj.r.squared
summary(a)$r.squared
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
m = summary(lm(y~x))
print(paste('R-squared: ', m$r.squared))
print(paste('R-squared: ', round(m$r.squared, 3))
print(paste('R-squared: ', round(m$r.squared, 3)))
print(paste('R-squared: ', round(m$r.squared, 3)))
predict(m, list(x = 5))
m = lm(y~x)
predict(m, list(x = 5))
print(paste('Prediction: ', predict(m, list(x = 5))))
m2 = lm(y~x+Gender)
sm2 = summary(m2)
print(paste('R-squared: ', round(sm2$r.squared, 3)))
print(paste('Prediction: ', predict(m2, list(x = 5, Gender = 'Female'))))
m2
summary(m2)
xaringan:::inf_mr()
getSymbols("AAPL")
library(quantmod)
install.packages('quantmod')
library(quantmod)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(tidyverse)
d <- read_csv('https://raw.githubusercontent.com/karlarao/forecast_examples/master/Amtrak%20data.csv')
# create a time series object, frequency = 12 means monthly time series
d = drop_na(d)
t <- ts(d$Ridership, start = 1991, frequency = 12)
autoplot(t)
library(forecast)
library(forecast)
autoplot(t)
# naive forecasting
pred1 <- naive(t, h =20)
autoplot(pred1)
summary(pred1)
library(quantmod)
getSymbols("AAPL")
AAPL
class(AAPL)
autoplot(AAPL)
autoplot(AAPL$AAPL.Open)
class(AAPL$AAPL.Open)
AAPL$AAPL.Open
plot(AAPL$AAPL.Open)
pred1 <- naive(AAPL$AAPL.Open, h =20)
pred1
autoplot(pred1)
plot(pred1)
Op(AAPL)
class(Op(AAPL))
arima
arima(AAPL$AAPL.Open, c(1,0,0))
price <- c(2,3,7,8,9,12,8,7)
AR1 <- arima(price,c(1,0,0))
AR1
arima.sim
?arima.sim
yt <- arima.sim(list(order=c(1,0,0), ar=.5), n=500)
plot(yt)
yt <- arima.sim(list(order=c(1,0,0), ar=1), n=500)
yt <- arima.sim(list(order=c(1,0,0), ar=0), n=500)
plot(yt)
yt <- arima.sim(list(order=c(1,0,0), ar=0.1), n=500)
plot(yt)
?naive
?ts
?naive
arima
?arima
arima(AAPL$AAPL.Open)
ts(AAPL$AAPL.Open, start = decimal_date(as.Date("2015-02-24")))
library(lubridate)
ts(AAPL$AAPL.Open, start = decimal_date(as.Date("2015-02-24")))
plot(ts(AAPL$AAPL.Open, start = decimal_date(as.Date("2015-02-24"))))
plot(ts(AAPL$AAPL.Open, start = decimal_date(as.Date("2015-02-24")), frequency = 365))
AAPL$AAPL.Open
plot(ts(AAPL$AAPL.Open, start = decimal_date(as.Date("2007-01-03")), frequency = 365))
library(quantmod)
getSymbols("AAPL")
t2 <- ts(AAPL.Open, start = decimal_date(as.Date("2007-01-03")), frequency = 365)
library(quantmod)
getSymbols("AAPL")
t2 <- ts(AAPL$Open, start = decimal_date(as.Date("2007-01-03")), frequency = 365)
library(quantmod)
getSymbols("AAPL")
t2 <- ts(AAPL$AAPL.Open, start = decimal_date(as.Date("2007-01-03")), frequency = 365)
pred2<- naive(t2, h =20)
autoplot(pred2)
summary(pred2)
AAPL$AAPL.Open
decimal_date(as.Date("2007-01-03"))
AAPL$AAPL.Open
class(AAPL$AAPL.Open)
?NAIVE
library(fable)
install.packages('fable')
goog <- tsibbledata::gafa_stock %>%
filter(Symbol == "GOOG", year(Date) >= 2015) %>%
# re-index on trading day since markets not open on weekends, holidays
arrange(Date) %>%
mutate(trading_day = row_number()) %>%
update_tsibble(index = trading_day, regular = TRUE)
library(fable)
goog <- tsibbledata::gafa_stock %>%
filter(Symbol == "GOOG", year(Date) >= 2015) %>%
# re-index on trading day since markets not open on weekends, holidays
arrange(Date) %>%
mutate(trading_day = row_number()) %>%
update_tsibble(index = trading_day, regular = TRUE)
goog <- tsibbledata::gafa_stock %>%
filter(Symbol == "GOOG", year(Date) >= 2015) %>%
# re-index on trading day since markets not open on weekends, holidays
arrange(Date) %>%
mutate(trading_day = row_number()) %>%
update_tsibble(index = trading_day, regular = TRUE)
goog <- tsibbledata::gafa_stock %>%
filter(Symbol == "GOOG", year(Date) >= 2015) %>%
# re-index on trading day since markets not open on weekends, holidays
arrange(Date) %>%
mutate(trading_day = row_number())
install.packages('tsibbledata')
goog <- tsibbledata::gafa_stock %>%
filter(Symbol == "GOOG", year(Date) >= 2015) %>%
# re-index on trading day since markets not open on weekends, holidays
arrange(Date) %>%
mutate(trading_day = row_number()) %>%
update_tsibble(index = trading_day, regular = TRUE)
library(tsibbledata)
goog <- tsibbledata::gafa_stock %>%
filter(Symbol == "GOOG", year(Date) >= 2015) %>%
# re-index on trading day since markets not open on weekends, holidays
arrange(Date) %>%
mutate(trading_day = row_number()) %>%
update_tsibble(index = trading_day, regular = TRUE)
goog <- tsibbledata::gafa_stock %>%
filter(Symbol == "GOOG", year(Date) >= 2015) %>%
# re-index on trading day since markets not open on weekends, holidays
arrange(Date) %>%
mutate(trading_day = row_number())
head(goog)
dim(goog)
# Segment with `filter()`, or `group_by()` + `slice()`.
goog_train <- goog %>% filter(year(Date) == 2015)
goog_test <- goog %>% filter(yearmonth(Date) == yearmonth("2016 Jan"))
library(tsibble)
# Segment with `filter()`, or `group_by()` + `slice()`.
goog_train <- goog %>% filter(year(Date) == 2015)
goog_test <- goog %>% filter(yearmonth(Date) == yearmonth("2016 Jan"))
# Train model
goog_mdl <- goog_train %>%
model(mdl_naive = NAIVE(Close))
# Generate predictions (forecast)
goog_fc <- goog_mdl %>%
forecast(new_data = goog_test)
goog_fc_2 <- goog_fc %>%
mutate(mu = map_dbl(Close, ~pluck(.x, "mu")),
sigma = map_dbl(Close, ~pluck(.x, "sigma")),
ci_025 = qnorm(.025, mu, sigma),
ci_100 = qnorm(.100, mu, sigma),
ci_900 = qnorm(.900, mu, sigma),
ci_975 = qnorm(.975, mu, sigma)) %>%
select(trading_day, Date, Close, mu, sigma, ci_025:ci_975)
tsibbledata::aus_production %>%
# same thing as
# filter(Quarter >= yearquarter("1970 Q1") & Quarter <= yearquarter("2004 Q4")) %>%
filter_index("1995 Q1" ~ "2007 Q4") %>%
model(Mean = MEAN(Beer),
Naive = NAIVE(Beer),
SNaive = SNAIVE(Beer),
Drift = RW(Beer ~ drift())) %>%
forecast(h = 8) %>%
ggplot(aes(x = Quarter)) +
geom_line(aes(y = .mean, color = .model), size = 1) +
geom_line(data = tsibbledata::aus_production %>% filter_index("1995 Q1" ~ "2009 Q4"),
aes(y = Beer),
color = "darkgrey", size = 1) +
theme_light() +
guides(color = guide_legend(title = "Forecast")) +
labs(title = "Simple forecast methods are useful benchmarks.",
x = NULL, y = NULL,
caption = "Source: Quarterly beer production (ML) from tsibbledata::aus_production.")
tsibbledata::aus_production %>%
# same thing as
# filter(Quarter >= yearquarter("1970 Q1") & Quarter <= yearquarter("2004 Q4")) %>%
filter_index("1995 Q1" ~ "2007 Q4")
?model
NAIVE(AAPL$AAPL.Open)
naive(AAPL$AAPL.Open)
model(NAIVE(AAPL$AAPL.Open))
model(n = NAIVE(AAPL$AAPL.Open))
tsibbledata::aus_production %>%
# same thing as
# filter(Quarter >= yearquarter("1970 Q1") & Quarter <= yearquarter("2004 Q4")) %>%
filter_index("1995 Q1" ~ "2007 Q4") %>%
model(Mean = MEAN(Beer),
Naive = NAIVE(Beer),
SNaive = SNAIVE(Beer),
Drift = RW(Beer ~ drift())) %>%
forecast(h = 8) %>%
ggplot(aes(x = Quarter)) +
geom_line(aes(y = .mean, color = .model), size = 1) +
geom_line(data = tsibbledata::aus_production %>% filter_index("1995 Q1" ~ "2009 Q4"),
aes(y = Beer),
color = "darkgrey", size = 1) +
theme_light() +
guides(color = guide_legend(title = "Forecast")) +
labs(title = "Simple forecast methods are useful benchmarks.",
x = NULL, y = NULL,
caption = "Source: Quarterly beer production (ML) from tsibbledata::aus_production.")
naive(t)
model(Mean = MEAN(AAPL),
Naive = NAIVE(AAPL),
SNaive = SNAIVE(AAPL)) %>%
forecast(h = 8)
NAIVE(AAPL$AAPL.Open) %>% forecast()
NAIVE(AAPL$AAPL.Open) %>% forecast(h=8)
NAIVE(AAPL$AAPL.Open)
forecast(NAIVE(AAPL$AAPL.Open))
tsibbledata::aus_production %>%
# same thing as
# filter(Quarter >= yearquarter("1970 Q1") & Quarter <= yearquarter("2004 Q4")) %>%
filter_index("1995 Q1" ~ "2007 Q4") %>%
model(Mean = MEAN(Beer),
Naive = NAIVE(Beer),
SNaive = SNAIVE(Beer),
Drift = RW(Beer ~ drift())) %>%
forecast(h = 8)
tsibbledata::aus_production %>%
# same thing as
# filter(Quarter >= yearquarter("1970 Q1") & Quarter <= yearquarter("2004 Q4")) %>%
filter_index("1995 Q1" ~ "2007 Q4") %>%
model(
Naive = NAIVE(Beer)) %>%
forecast(h = 8)
tsibbledata::aus_production %>%
# same thing as
# filter(Quarter >= yearquarter("1970 Q1") & Quarter <= yearquarter("2004 Q4")) %>%
filter_index("1995 Q1" ~ "2007 Q4") %>%
model(NAIVE(Beer)) %>%
forecast(h = 8)
tsibbledata::aus_production %>%
# same thing as
# filter(Quarter >= yearquarter("1970 Q1") & Quarter <= yearquarter("2004 Q4")) %>%
filter_index("1995 Q1" ~ "2007 Q4") %>%
NAIVE(Beer) %>%
forecast(h = 8)
tsibbledata::aus_production %>%
# same thing as
# filter(Quarter >= yearquarter("1970 Q1") & Quarter <= yearquarter("2004 Q4")) %>%
filter_index("1995 Q1" ~ "2007 Q4") %>%
model(NAIVE(Beer)) %>%
forecast(h = 8)
AAPL$AAPL.Open %>%     model(NAIVE()) %>%
forecast(h = 8)
tsibbledata::aus_production %>%
# same thing as
# filter(Quarter >= yearquarter("1970 Q1") & Quarter <= yearquarter("2004 Q4")) %>%
filter_index("1995 Q1" ~ "2007 Q4")
as_tsibble(AAPL$AAPL.Open)
window
?window
prices <- c(132.45, 130.85, 130.00, 129.55, 130.85)
dates <- as.Date(c(
"2010-01-04", "2010-01-05", "2010-01-06",
"2010-01-07", "2010-01-08"
))
ibm.daily <- zoo(prices, dates)
ibm.daily
class(ibm.daily)
AAPL$AAPL.Open
autoplot(AAPL$AAPL.Open)
plot(AAPL$AAPL.Open)
autoplot(AAPL$AAPL.Open)
plot(AAPL$AAPL.Open)
plot.xts(AAPL$AAPL.Open)
library(quantmod)
getSymbols("AAPL")
t2 <- ts(AAPL$AAPL.Open, start = decimal_date(as.Date("2007-01-03")), frequency = 365)
pred2<- naive(t2, h =20)
autoplot(pred2)
summary(pred2)
goog_train
goog_test
class(goog_train)
goog_mdl <- goog_train %>%
model(mdl_naive = NAIVE(Close))
Close
goog_train %>%
model(mdl_naive = NAIVE(Close))
goog_mdl <- goog_train %>%
model(mdl_naive = NAIVE(Close))
ts(AAPL$AAPL.Open)
decimal_date(as.Date("2007-01-03"))
as.Date(2007.005)
date_decimal(2007.005)
date_decimal(2007.005)
days <- seq(as.Date("2014-01-01"), length = 668, by = "day")
days
sales_xts <- xts(sales, order.by = days)
t2 = AAPL$AAPL.Open
train <- t2[index(sales_xts) <= "2015-07-01"]
t2 = AAPL$AAPL.Open
train <- t2[index(t2) <= "2015-07-01"]
t2
class(t2)
train <- t2[index(t2) <= "2015-07-01"]
d <- read_csv('german_credit.csv')
library(tidyverse)
library(caret)
library(class)
d <- read_csv('german_credit.csv')
setwd("C:/Users/sonou/Dropbox/git/SRM/AYU")
d <- read_csv('german_credit.csv')
d <- rename(d, target=credit_amount) # Set credit_amout as the target variable
df = select(d, -target) # select the set of predictors for pre-processing
df = knn_prepared(df)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
# dummy all categorical variables
# normalize all continuous variables to range 0 and 1
knn_prepared = function(d)
{
library(tidyverse)
library(fastDummies)
d_numeric = d %>% summarise_if(is.numeric, function(x){(x-min(x))/(max(x)-min(x))})
d_category = d %>% select_if(~!is.numeric(.))
d_category_dummy = dummy_cols(d_category, remove_first_dummy = TRUE, remove_selected_columns=TRUE)
return(as_tibble(cbind(d_numeric, d_category_dummy)))
}
d <- read_csv('german_credit.csv')
d <- rename(d, target=credit_amount) # Set credit_amout as the target variable
df = select(d, -target) # select the set of predictors for pre-processing
df = knn_prepared(df)
df$target = d$target
library(caret)
set.seed(2020)
splitIndex <- createDataPartition(df$target, p = .70,
list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
pred = knn(train = df_train, test = df_test, cl = df_train$target, k = 1)
postResample(pred = pred$predictions, obs = df_test$target)
pred
knn.reg(train = select(df_train, -target), test = df_test, y = select(df_train, target), k = 1)
library(FNN)
install.packages(FNN)
install.packages(F'NN)
install.packages('FNN')
library(FNN)
knn.reg(train = select(df_train, -target), test = df_test, y = select(df_train, target), k = 1)
select(df_train, -target)
df_test
knn.reg(train = select(df_train, -target), test = select(df_test, -target), y = select(df_train, target), k = 1)
knn.reg(train = select(df_train, -target), test = select(df_test, -target), y = select(df_train, target), k = 1)
select(df_test, -target)
knn.reg(train = select(df_train, -target), test = select(df_test, -target), y = select(df_train, target), k = 1)
select(df_train, target)
knn.reg(train = select(df_train, -target), test = select(df_test, -target), y = df_train$target, k = 1)
knn.reg(train = select(df_train, -target), test = select(df_test, -target), y = df_train$target, k = 1)
postResample(pred = pred, obs = df_test$target)
pred
pred = knn.reg(train = select(df_train, -target), test = select(df_test, -target), y = df_train$target, k = 1)
pred
postResample(pred = pred, obs = df_test$target)
pred
class(pred)
pred$call
pred$pred
class(pred$pred)
postResample(pred = pred$pred, obs = df_test$target)
pred = knn.reg(train = select(df_train, -target), test = select(df_test, -target), y = df_train$target, k = 1)
postResample(pred = pred$pred, obs = df_test$target)
pred = knn.reg(train = select(df_train, -target), test = select(df_test, -target), y = df_train$target, k = 10)
postResample(pred = pred$pred, obs = df_test$target)
pred = knn.reg(train = select(df_train, -target), test = select(df_test, -target), y = df_train$target, k = 20)
postResample(pred = pred$pred, obs = df_test$target)
pred = knn.reg(train = select(df_train, -target), test = select(df_test, -target), y = df_train$target, k = 100)
postResample(pred = pred$pred, obs = df_test$target)
pred = knn.reg(train = select(df_train, -target), test = select(df_test, -target), y = df_train$target, k = 200)
postResample(pred = pred$pred, obs = df_test$target)
pred = knn.reg(train = select(df_train, -target), test = select(df_test, -target), y = df_train$target, k = 300)
postResample(pred = pred$pred, obs = df_test$target)
pred = knn.reg(train = select(df_train, -target), test = select(df_test, -target), y = df_train$target, k = 500)
postResample(pred = pred$pred, obs = df_test$target)
pred = knn.reg(train = select(df_train, -target), test = select(df_test, -target), y = df_train$target, k = 1000)
pred = knn.reg(train = select(df_train, -target), test = select(df_test, -target), y = df_train$target, k = 800)
pred = knn.reg(train = select(df_train, -target), test = select(df_test, -target), y = df_train$target, k = 600)
postResample(pred = pred$pred, obs = df_test$target)
d <- read_csv('german_credit.csv')
d <- rename(d, target=credit_amount) # Set credit_amout as the target variable
df = select(d, -target) # select the set of predictors for pre-processing
df = knn_prepared(df)
df$target = d$target
library(caret)
set.seed(2020)
splitIndex <- createDataPartition(df$target, p = .70,
list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
pred = knn.reg(train = select(df_train, -target), test = select(df_test, -target), y = df_train$target, k = 10)
postResample(pred = pred$pred, obs = df_test$target)
?knn
library(tidyverse)
library(caret)
library(FNN)
d <- read_csv('german_credit.csv')
d <- rename(d, target=class) # rename the target variable as target
d$target = as.factor(d$target)
df = select(d, -target)
df = knn_prepared(df)
df$target = d$target
library(caret)
set.seed(2020)
splitIndex <- createDataPartition(df$target, p = .70,
list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
pred = knn(train = df_train, test = df_test, cl = df_train$target, k = 1)
pred = knn(select(df_train, -target), test = select(df_test, -target), y = df_train$target)
pred = knn(select(df_train, -target), test = select(df_test, -target), cl = df_train$target)
pred
class(pred)
library(tidyverse)
library(caret)
library(class)
d <- read_csv('german_credit.csv')
d <- rename(d, target=class) # rename the target variable as target
d$target = as.factor(d$target)
df = select(d, -target)
df = knn_prepared(df)
df$target = d$target
library(caret)
set.seed(2020)
splitIndex <- createDataPartition(df$target, p = .70,
list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
pred = knn(select(df_train, -target), test = select(df_test, -target), cl = df_train$target)
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = "1")
cm$overall[1]
?knn
USArrests
df <- USArrests
df <- na.omit(df)
#scale each variable to have a mean of 0 and sd of 1
df <- scale(df)
clust <- agnes(df, method = "ward")
library(cluster)
df <- USArrests
df <- na.omit(df)
#scale each variable to have a mean of 0 and sd of 1
df <- scale(df)
clust <- agnes(df, method = "ward")
#produce dendrogram
pltree(clust, cex = 0.6, hang = -1, main = "Dendrogram")
pltree(clust, cex = 0.6, hang = -1, main = "Dendrogram")
#calculate gap statistic for each number of clusters (up to 10 clusters)
gap_stat <- clusGap(df, FUN = hcut, nstart = 25, K.max = 10, B = 50)
movies
